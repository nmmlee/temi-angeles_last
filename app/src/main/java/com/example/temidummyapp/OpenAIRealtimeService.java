package com.example.temidummyapp;

import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.AudioTrack;
import android.media.MediaRecorder;
import android.os.Handler;
import android.os.Looper;
import android.util.Base64;
import android.util.Log;

import com.google.gson.Gson;
import com.google.gson.JsonArray;
import com.google.gson.JsonObject;

import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.util.concurrent.TimeUnit;

import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.Response;
import okhttp3.WebSocket;
import okhttp3.WebSocketListener;
import okio.ByteString;

/**
 * OpenAI Realtime API ì„œë¹„ìŠ¤
 * WebSocketì„ í†µí•œ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìŒì„± ëŒ€í™”
 */
public class OpenAIRealtimeService {
    private static final String TAG = "OpenAIRealtimeService";
    private static final String REALTIME_API_URL = "wss://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-10-01";

    // ì˜¤ë””ì˜¤ ì„¤ì •
    private static final int SAMPLE_RATE = 24000; // OpenAI Realtime API ìš”êµ¬ì‚¬í•­
    private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;
    private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;

    private final OkHttpClient client;
    private final Gson gson;
    private final Handler mainHandler;
    private final String apiKey;

    private WebSocket webSocket;
    private AudioRecord audioRecord;
    private AudioTrack audioTrack;
    private boolean isStreaming = false;
    private boolean isMicrophonePaused = false; // ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœ
    private RealtimeCallback callback;

    // ìŒì•• ê°ì§€
    private float currentAudioLevel = 0.0f;

    public interface RealtimeCallback {
        void onConnected();

        void onAudioLevelChanged(float level); // 0.0 ~ 1.0

        void onTranscriptReceived(String transcript);

        void onResponseStarted();

        void onResponseReceived(String response);

        void onResponseComplete();

        void onError(String error);

        void onDisconnected();
    }

    public OpenAIRealtimeService(String apiKey) {
        this.apiKey = apiKey;
        this.client = new OkHttpClient.Builder()
                .readTimeout(0, TimeUnit.MILLISECONDS)
                .build();
        this.gson = new Gson();
        this.mainHandler = new Handler(Looper.getMainLooper());
    }

    public void setCallback(RealtimeCallback callback) {
        this.callback = callback;
    }

    /**
     * Realtime API ì—°ê²°
     */
    public void connect() {
        Request request = new Request.Builder()
                .url(REALTIME_API_URL)
                .addHeader("Authorization", "Bearer " + apiKey)
                .addHeader("OpenAI-Beta", "realtime=v1")
                .build();

        webSocket = client.newWebSocket(request, new WebSocketListener() {
            @Override
            public void onOpen(WebSocket webSocket, Response response) {
                Log.d(TAG, "WebSocket ì—°ê²°ë¨");

                // ì„¸ì…˜ ì„¤ì • ì „ì†¡
                sendSessionUpdate();

                if (callback != null) {
                    mainHandler.post(callback::onConnected);
                }
            }

            @Override
            public void onMessage(WebSocket webSocket, String text) {
                handleTextMessage(text);
            }

            @Override
            public void onMessage(WebSocket webSocket, ByteString bytes) {
                handleBinaryMessage(bytes);
            }

            @Override
            public void onFailure(WebSocket webSocket, Throwable t, Response response) {
                Log.e(TAG, "WebSocket ì˜¤ë¥˜", t);
                if (callback != null) {
                    mainHandler.post(() -> callback.onError(t.getMessage()));
                }
            }

            @Override
            public void onClosed(WebSocket webSocket, int code, String reason) {
                Log.d(TAG, "WebSocket ì¢…ë£Œë¨: " + reason);
                if (callback != null) {
                    mainHandler.post(callback::onDisconnected);
                }
            }
        });
    }

    /**
     * ì„¸ì…˜ ì„¤ì • ì „ì†¡ (RAG ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í¬í•¨)
     */
    private void sendSessionUpdate() {
        // OpenAIServiceì˜ AUDIO_SYSTEM_PROMPT ì‚¬ìš© (ìŒì„± ëŒ€í™”ìš© ê°„ê²°í•œ ë²„ì „)
        String systemPrompt = getAudioSystemPrompt();

        JsonObject sessionUpdate = new JsonObject();
        sessionUpdate.addProperty("type", "session.update");

        JsonObject session = new JsonObject();

        // ëª¨ë‹¬ë¦¬í‹° ì„¤ì • (í…ìŠ¤íŠ¸ + ì˜¤ë””ì˜¤) - ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì „ì†¡
        JsonArray modalities = new JsonArray();
        modalities.add("text");
        modalities.add("audio");
        session.add("modalities", modalities);

        // ìŒì„± ì„¤ì •
        session.addProperty("voice", "alloy"); // alloy, echo, fable, onyx, nova, shimmer

        // ì§€ì‹œì‚¬í•­ (RAG ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸)
        session.addProperty("instructions", systemPrompt);

        // ì…ë ¥ ì˜¤ë””ì˜¤ í˜•ì‹ - ë¬¸ìì—´ë¡œ ì „ì†¡
        session.addProperty("input_audio_format", "pcm16");

        // ì¶œë ¥ ì˜¤ë””ì˜¤ í˜•ì‹ - ë¬¸ìì—´ë¡œ ì „ì†¡
        session.addProperty("output_audio_format", "pcm16");

        // ì…ë ¥ ìŒì„± ì „ì‚¬ í™œì„±í™” (ì‚¬ìš©ì ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜)
        JsonObject inputAudioTranscription = new JsonObject();
        inputAudioTranscription.addProperty("model", "whisper-1");
        session.add("input_audio_transcription", inputAudioTranscription);

        // ì‘ë‹µ ìµœëŒ€ í† í° ìˆ˜ ì„¤ì • (ë‹µë³€ì´ ëŠì–´ì§€ì§€ ì•Šë„ë¡)
        session.addProperty("max_response_output_tokens", 4096); // ì¶©ë¶„í•œ ë‹µë³€ ê¸¸ì´ í™•ë³´

        // ì˜¨ë„ ì„¤ì • (ìŒì„± ëŒ€í™”ìš© - ê°„ê²°í•˜ê³  ì¼ê´€ë˜ê²Œ)
        session.addProperty("temperature", 0.6);

        // VAD (Voice Activity Detection) ì„¤ì •
        // í–‰ì‚¬ì¥ í™˜ê²½ì— ìµœì í™” (ì‹œë„ëŸ¬ìš´ í™˜ê²½ + ì ì ˆí•œ ëŒ€ê¸° ì‹œê°„)
        JsonObject turnDetection = new JsonObject();
        turnDetection.addProperty("type", "server_vad");
        turnDetection.addProperty("threshold", 0.75); // ë†’ì€ ë¯¼ê°ë„ (ì†ŒìŒ í•„í„°ë§ ê°•í™”)
        turnDetection.addProperty("prefix_padding_ms", 800); // ë°œí™” ì‹œì‘ ì „ 800ms íŒ¨ë”© (ë§ ì‹œì‘ ë³´í˜¸)
        turnDetection.addProperty("silence_duration_ms", 3000); // 3ì´ˆ ì¹¨ë¬µ í›„ í„´ ì¢…ë£Œ (ì ì ˆí•œ ì‘ë‹µ ì†ë„)
        session.add("turn_detection", turnDetection);

        sessionUpdate.add("session", session);

        String message = gson.toJson(sessionUpdate);
        webSocket.send(message);
        Log.d(TAG, "ì„¸ì…˜ ì„¤ì • ì „ì†¡ ì™„ë£Œ (RAG í¬í•¨)");
    }

    /**
     * OpenAIServiceì˜ AUDIO_SYSTEM_PROMPT ê°€ì ¸ì˜¤ê¸° (ìŒì„± ëŒ€í™”ìš©)
     */
    private String getAudioSystemPrompt() {
        // OpenAIService ì¸ìŠ¤í„´ìŠ¤ë¥¼ í†µí•´ ìŒì„± ëŒ€í™”ìš© í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        OpenAIService openAIService = new OpenAIService();
        return openAIService.getAudioSystemPrompt();
    }

    /**
     * í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
     */
    private void handleTextMessage(String text) {
        try {
            JsonObject json = gson.fromJson(text, JsonObject.class);
            String type = json.has("type") ? json.get("type").getAsString() : "";

            Log.d(TAG, "ìˆ˜ì‹  ë©”ì‹œì§€ íƒ€ì…: " + type);

            switch (type) {
                case "session.created":
                case "session.updated":
                    Log.d(TAG, "âœ… ì„¸ì…˜ ì¤€ë¹„ë¨");
                    break;

                case "conversation.item.input_audio_transcription.completed":
                    // ì‚¬ìš©ì ìŒì„± ì¸ì‹ ê²°ê³¼
                    if (json.has("transcript")) {
                        String transcript = json.get("transcript").getAsString();
                        Log.d(TAG, "ğŸ“ ì‚¬ìš©ì ìŒì„± ì¸ì‹: " + transcript);
                        if (callback != null) {
                            mainHandler.post(() -> callback.onTranscriptReceived(transcript));
                        }
                    }
                    break;

                case "response.created":
                    // AI ì‘ë‹µ ìƒì„± ì‹œì‘
                    Log.d(TAG, "ğŸ¯ AI ì‘ë‹µ ìƒì„± ì‹œì‘");
                    if (callback != null) {
                        mainHandler.post(callback::onResponseStarted);
                    }
                    break;

                case "response.audio_transcript.delta":
                    // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¼
                    if (json.has("delta")) {
                        String delta = json.get("delta").getAsString();
                        Log.d(TAG, "ğŸ“¤ AI í…ìŠ¤íŠ¸ ë¸íƒ€: " + delta);
                        if (callback != null) {
                            mainHandler.post(() -> callback.onResponseReceived(delta));
                        }
                    }
                    break;

                case "response.audio_transcript.done":
                    // AI ì‘ë‹µ í…ìŠ¤íŠ¸ ì™„ë£Œ
                    Log.d(TAG, "âœ… AI í…ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ");
                    break;

                case "response.audio.delta":
                    // AI ìŒì„± ìŠ¤íŠ¸ë¦¼ (Base64 ì¸ì½”ë”©ëœ PCM16 ë°ì´í„°)
                    if (json.has("delta")) {
                        String audioBase64 = json.get("delta").getAsString();
                        playAudioChunk(audioBase64);
                    }
                    break;

                case "response.audio.done":
                    // AI ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
                    Log.d(TAG, "ğŸ”Š AI ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ");
                    break;

                case "response.done":
                    // AI ì‘ë‹µ ì™„ì „ ì™„ë£Œ (í…ìŠ¤íŠ¸ + ìŒì„± ëª¨ë‘)
                    Log.d(TAG, "âœ… AI ì‘ë‹µ ì™„ì „ ì™„ë£Œ");
                    if (callback != null) {
                        mainHandler.post(callback::onResponseComplete);
                    }
                    break;

                case "error":
                    // ì˜¤ë¥˜ ë°œìƒ
                    String error = json.has("error") ? json.get("error").toString() : "Unknown error";
                    Log.e(TAG, "âŒ ì˜¤ë¥˜ ë°œìƒ: " + error);
                    if (callback != null) {
                        mainHandler.post(() -> callback.onError(error));
                    }
                    break;

                default:
                    Log.d(TAG, "âš ï¸ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë©”ì‹œì§€ íƒ€ì…: " + type);
                    break;
            }
        } catch (Exception e) {
            Log.e(TAG, "ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜", e);
        }
    }

    /**
     * ë°”ì´ë„ˆë¦¬ ë©”ì‹œì§€ ì²˜ë¦¬
     */
    private void handleBinaryMessage(ByteString bytes) {
        // ì˜¤ë””ì˜¤ ë°ì´í„° ì²˜ë¦¬
        Log.d(TAG, "ë°”ì´ë„ˆë¦¬ ë°ì´í„° ìˆ˜ì‹ : " + bytes.size() + " bytes");
    }

    /**
     * ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
     */
    public void startAudioStreaming() {
        if (isStreaming) {
            return;
        }

        isStreaming = true;

        new Thread(() -> {
            try {
                int bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);
                audioRecord = new AudioRecord(MediaRecorder.AudioSource.MIC, SAMPLE_RATE, CHANNEL_CONFIG,
                        AUDIO_FORMAT, bufferSize);

                audioRecord.startRecording();
                Log.d(TAG, "ì˜¤ë””ì˜¤ ë…¹ìŒ ì‹œì‘");

                byte[] buffer = new byte[bufferSize];

                while (isStreaming) {
                    // ë§ˆì´í¬ê°€ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœë©´ ë°ì´í„° ì½ì§€ë§Œ ì „ì†¡í•˜ì§€ ì•ŠìŒ
                    int bytesRead = audioRecord.read(buffer, 0, buffer.length);

                    if (bytesRead > 0 && !isMicrophonePaused) {
                        // ìŒì•• ê³„ì‚°
                        calculateAudioLevel(buffer, bytesRead);

                        // Base64 ì¸ì½”ë”©
                        String audioBase64 = Base64.encodeToString(buffer, 0, bytesRead, Base64.NO_WRAP);

                        // WebSocketìœ¼ë¡œ ì „ì†¡ (ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ ìƒíƒœê°€ ì•„ë‹ ë•Œë§Œ)
                        JsonObject audioAppend = new JsonObject();
                        audioAppend.addProperty("type", "input_audio_buffer.append");
                        audioAppend.addProperty("audio", audioBase64);

                        webSocket.send(gson.toJson(audioAppend));
                    } else if (isMicrophonePaused) {
                        // ì¼ì‹œ ì¤‘ì§€ ì¤‘ì—ëŠ” ìŒì•• ë ˆë²¨ 0ìœ¼ë¡œ ì„¤ì •
                        currentAudioLevel = 0.0f;
                        if (callback != null) {
                            mainHandler.post(() -> callback.onAudioLevelChanged(0.0f));
                        }
                    }
                }
            } catch (Exception e) {
                Log.e(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜", e);
                if (callback != null) {
                    mainHandler.post(() -> callback.onError("ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: " + e.getMessage()));
                }
            }
        }).start();
    }

    /**
     * ìŒì•• ê³„ì‚° (0.0 ~ 1.0)
     */
    private void calculateAudioLevel(byte[] buffer, int length) {
        if (length == 0) {
            currentAudioLevel = 0.0f;
            return;
        }

        // PCM16 ë°ì´í„°ë¥¼ shortë¡œ ë³€í™˜í•˜ì—¬ RMS ê³„ì‚°
        long sum = 0;
        int sampleCount = length / 2;

        for (int i = 0; i < length - 1; i += 2) {
            short sample = (short) ((buffer[i + 1] << 8) | (buffer[i] & 0xFF));
            sum += sample * sample;
        }

        double rms = Math.sqrt((double) sum / sampleCount);
        double db = 20 * Math.log10(rms / 32768.0); // -60dB ~ 0dB ë²”ìœ„

        // 0.0 ~ 1.0ìœ¼ë¡œ ì •ê·œí™” (-60dB ~ 0dB -> 0.0 ~ 1.0)
        float normalizedLevel = (float) Math.max(0.0, Math.min(1.0, (db + 60) / 60));

        // ë¶€ë“œëŸ¬ìš´ ì „í™˜
        currentAudioLevel = currentAudioLevel * 0.7f + normalizedLevel * 0.3f;

        if (callback != null) {
            mainHandler.post(() -> callback.onAudioLevelChanged(currentAudioLevel));
        }
    }

    /**
     * AI ìŒì„± ì¬ìƒ
     */
    private void playAudioChunk(String audioBase64) {
        try {
            byte[] audioData = Base64.decode(audioBase64, Base64.NO_WRAP);
            Log.d(TAG, "ğŸ”Š ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹ : " + audioData.length + " bytes");

            if (audioTrack == null) {
                int minBufferSize = AudioTrack.getMinBufferSize(SAMPLE_RATE,
                        AudioFormat.CHANNEL_OUT_MONO, AUDIO_FORMAT);
                
                // ë²„í¼ í¬ê¸°ë¥¼ 4ë°°ë¡œ ëŠ˜ë ¤ì„œ ëŠê¹€ ë°©ì§€
                int bufferSize = minBufferSize * 4;
                
                Log.d(TAG, "ğŸµ AudioTrack ìƒì„± (ë²„í¼: " + bufferSize + " bytes)");

                audioTrack = new AudioTrack(
                        android.media.AudioManager.STREAM_MUSIC,
                        SAMPLE_RATE,
                        AudioFormat.CHANNEL_OUT_MONO,
                        AUDIO_FORMAT,
                        bufferSize,
                        AudioTrack.MODE_STREAM);

                audioTrack.play();
                Log.d(TAG, "â–¶ï¸ AudioTrack ì¬ìƒ ì‹œì‘");
            }

            // ì˜¤ë””ì˜¤ ë°ì´í„° ì“°ê¸°
            int written = audioTrack.write(audioData, 0, audioData.length);
            if (written < 0) {
                Log.e(TAG, "âŒ AudioTrack write ì‹¤íŒ¨: " + written);
            }
        } catch (Exception e) {
            Log.e(TAG, "âŒ ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜", e);
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ (ìˆœì°¨ì  ì¢…ë£Œ)
     */
    public void stopAudioStreaming() {
        Log.d(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì‹œì‘");
        
        // 1. ìŠ¤íŠ¸ë¦¬ë° í”Œë˜ê·¸ ë„ê¸° (ë…¹ìŒ ë£¨í”„ ì¤‘ë‹¨)
        isStreaming = false;

        // 2. ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘ì§€ (ì§„í–‰ ì¤‘ì¸ ì¶œë ¥ ì¦‰ì‹œ ì¤‘ë‹¨)
        if (audioTrack != null) {
            try {
                Log.d(TAG, "AudioTrack ì¤‘ì§€ ì‹œì‘");
                
                // ì¦‰ì‹œ ë³¼ë¥¨ 0ìœ¼ë¡œ ì„¤ì • (ë¬´ìŒ)
                audioTrack.setStereoVolume(0.0f, 0.0f);
                
                // ì¬ìƒ ì¤‘ì¸ ì˜¤ë””ì˜¤ ì¦‰ì‹œ í”ŒëŸ¬ì‹œ
                audioTrack.pause();
                audioTrack.flush();
                audioTrack.stop();
                audioTrack.release();
                audioTrack = null;
                
                Log.d(TAG, "AudioTrack ì¤‘ì§€ ì™„ë£Œ");
            } catch (IllegalStateException e) {
                Log.w(TAG, "AudioTrackì´ ì´ë¯¸ í•´ì œë¨", e);
            } catch (Exception e) {
                Log.e(TAG, "AudioTrack ì¤‘ì§€ ì˜¤ë¥˜", e);
            }
        }

        // 3. ì˜¤ë””ì˜¤ ë…¹ìŒ ì¤‘ì§€
        if (audioRecord != null) {
            try {
                Log.d(TAG, "AudioRecord ì¤‘ì§€ ì‹œì‘");
                
                // ë…¹ìŒ ìƒíƒœ í™•ì¸ í›„ ì¤‘ì§€
                if (audioRecord.getRecordingState() == AudioRecord.RECORDSTATE_RECORDING) {
                    audioRecord.stop();
                }
                audioRecord.release();
                audioRecord = null;
                
                Log.d(TAG, "AudioRecord ì¤‘ì§€ ì™„ë£Œ");
            } catch (IllegalStateException e) {
                Log.w(TAG, "AudioRecordê°€ ì´ë¯¸ í•´ì œë¨", e);
            } catch (Exception e) {
                Log.e(TAG, "AudioRecord ì¤‘ì§€ ì˜¤ë¥˜", e);
            }
        }

        // 4. ìŒì•• ë ˆë²¨ ì´ˆê¸°í™”
        currentAudioLevel = 0.0f;
        
        Log.d(TAG, "ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì§€ ì™„ë£Œ");
    }

    /**
     * WebSocket ì—°ê²° ì¢…ë£Œ (ìˆœì°¨ì  ì¢…ë£Œ)
     */
    public void disconnect() {
        Log.d(TAG, "WebSocket ì—°ê²° ì¢…ë£Œ ì‹œì‘");
        
        // 1. ì˜¤ë””ì˜¤ ë¨¼ì € ì¤‘ì§€
        stopAudioStreaming();

        // 2. WebSocket ì¢…ë£Œ
        if (webSocket != null) {
            try {
                Log.d(TAG, "WebSocket close í˜¸ì¶œ");
                webSocket.close(1000, "ì •ìƒ ì¢…ë£Œ");
                webSocket = null;
                Log.d(TAG, "WebSocket ì¢…ë£Œ ì™„ë£Œ");
            } catch (Exception e) {
                Log.e(TAG, "WebSocket ì¢…ë£Œ ì˜¤ë¥˜", e);
                webSocket = null; // ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ nullë¡œ ì„¤ì •
            }
        }

        // 3. OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        try {
            client.dispatcher().executorService().shutdown();
            Log.d(TAG, "OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ");
        } catch (Exception e) {
            Log.e(TAG, "OkHttp ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì˜¤ë¥˜", e);
        }
        
        Log.d(TAG, "WebSocket ì—°ê²° ì¢…ë£Œ ì™„ë£Œ");
    }

    /**
     * ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ (AIê°€ ë§í•  ë•Œ - ì—ì½” ë°©ì§€)
     */
    public void pauseMicrophone() {
        if (!isMicrophonePaused && isStreaming) {
            isMicrophonePaused = true;
            Log.d(TAG, "ğŸ”‡ ë§ˆì´í¬ ì¼ì‹œ ì¤‘ì§€ (AI ì‘ë‹µ ì¤‘ - ì—ì½” ë°©ì§€)");
        }
    }

    /**
     * ë§ˆì´í¬ ì¬ê°œ (AIê°€ ë§ ëë‚¬ì„ ë•Œ)
     */
    public void resumeMicrophone() {
        if (isMicrophonePaused && isStreaming) {
            isMicrophonePaused = false;
            Log.d(TAG, "ğŸ¤ ë§ˆì´í¬ ì¬ê°œ (ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°)");
        }
    }

    /**
     * ì˜¤ë””ì˜¤ ì¶œë ¥ ì¦‰ì‹œ ìŒì†Œê±° (ë‚˜ê°€ê¸° ë²„íŠ¼ ë“±)
     * ë©”ì¸ ìŠ¤ë ˆë“œì—ì„œ ì¦‰ì‹œ í˜¸ì¶œë˜ì–´ì•¼ í•¨
     */
    public void muteAudioImmediately() {
        Log.d(TAG, "ğŸ”‡ ì˜¤ë””ì˜¤ ì¶œë ¥ ì¦‰ì‹œ ìŒì†Œê±° ìš”ì²­");
        
        if (audioTrack != null) {
            try {
                // 1. ë³¼ë¥¨ì„ ì¦‰ì‹œ 0ìœ¼ë¡œ
                audioTrack.setStereoVolume(0.0f, 0.0f);
                Log.d(TAG, "ğŸ”‡ ë³¼ë¥¨ 0 ì„¤ì • ì™„ë£Œ");
                
                // 2. ì¬ìƒ ì¼ì‹œ ì •ì§€
                audioTrack.pause();
                Log.d(TAG, "â¸ï¸ AudioTrack ì¼ì‹œ ì •ì§€");
                
                // 3. ë²„í¼ ë¹„ìš°ê¸° (ì§„í–‰ ì¤‘ì¸ ìŒì„± ì œê±°)
                audioTrack.flush();
                Log.d(TAG, "ğŸ—‘ï¸ AudioTrack ë²„í¼ ë¹„ìš°ê¸° ì™„ë£Œ");
                
            } catch (IllegalStateException e) {
                Log.w(TAG, "âš ï¸ AudioTrackì´ ì´ë¯¸ ì •ì§€ë¨", e);
            } catch (Exception e) {
                Log.e(TAG, "âŒ ì˜¤ë””ì˜¤ ìŒì†Œê±° ì˜¤ë¥˜", e);
            }
        } else {
            Log.d(TAG, "â„¹ï¸ AudioTrackì´ null (ì´ë¯¸ ì¢…ë£Œë¨)");
        }
    }
}

